# SOME DESCRIPTIVE TITLE.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"Report-Msgid-Bugs-To: http://bugs.kde.org\n"
"POT-Creation-Date: 2017-01-20 18:23+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <kde-i18n-doc@kde.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. Tag: title
#: tuning_memory.xml:45
#, no-c-format
msgid "Tuning the Memory Management Subsystem"
msgstr ""

#. Tag: para
#: tuning_memory.xml:52
#, no-c-format
msgid ""
"To understand and tune the memory management behavior of the kernel, it is "
"important to first have an overview of how it works and cooperates with "
"other subsystems."
msgstr ""

#. Tag: remark
#: tuning_memory.xml:58
#, no-c-format
msgid ""
"sknorr, 2014-08-21: Using VM for \"virtual memory manager\" is really "
"dangerous - everyone knows that VM means \"virtual machine\" and half of the "
"people reading this chapter might skip this prargraph and be completely "
"confused. At least use VMM or shorten \"memory management subsystem\" to "
"\"memory subsystem\", the latter of which I think should be short enough."
msgstr ""

#. Tag: para
#: tuning_memory.xml:63
#, no-c-format
msgid ""
"The memory management subsystem, also called the virtual memory manager, "
"will subsequently be called <quote>VM</quote>. The role of the VM is to "
"manage the allocation of physical memory (RAM) for the entire kernel and "
"user programs. It is also responsible for providing a virtual memory "
"environment for user processes (managed via POSIX APIs with Linux "
"extensions). Finally, the VM is responsible for freeing up RAM when there is "
"a shortage, either by trimming caches or swapping out <quote>anonymous</"
"quote> memory."
msgstr ""

#. Tag: para
#: tuning_memory.xml:73
#, no-c-format
msgid ""
"The most important thing to understand when examining and tuning VM is how "
"its caches are managed. The basic goal of the VM's caches is to minimize the "
"cost of I/O as generated by swapping and file system operations (including "
"network file systems). This is achieved by avoiding I/O completely, or by "
"submitting I/O in better patterns."
msgstr ""

#. Tag: para
#: tuning_memory.xml:80
#, no-c-format
msgid ""
"Free memory will be used and filled up by these caches as required. The more "
"memory is available for caches and anonymous memory, the more effectively "
"caches and swapping will operate. However, if a memory shortage is "
"encountered, caches will be trimmed or memory will be swapped out."
msgstr ""

#. Tag: para
#: tuning_memory.xml:87
#, no-c-format
msgid ""
"For a particular workload, the first thing that can be done to improve "
"performance is to increase memory and reduce the frequency that memory must "
"be trimmed or swapped. The second thing is to change the way caches are "
"managed by changing kernel parameters."
msgstr ""

#. Tag: para
#: tuning_memory.xml:93
#, no-c-format
msgid ""
"Finally, the workload itself should be examined and tuned as well. If an "
"application is allowed to run more processes or threads, effectiveness of VM "
"caches can be reduced, if each process is operating in its own area of the "
"file system. Memory overheads are also increased. If applications allocate "
"their own buffers or caches, larger caches will mean that less memory is "
"available for VM caches. However, more processes and threads can mean more "
"opportunity to overlap and pipeline I/O, and may take better advantage of "
"multiple cores. Experimentation will be required for the best results."
msgstr ""

#. Tag: title
#: tuning_memory.xml:105
#, no-c-format
msgid "Memory Usage"
msgstr ""

#. Tag: para
#: tuning_memory.xml:107
#, no-c-format
msgid ""
"Memory allocations in general can be characterized as <quote>pinned</quote> "
"(also known as <quote>unreclaimable</quote>), <quote>reclaimable</quote> or "
"<quote>swappable</quote>."
msgstr ""

#. Tag: title
#: tuning_memory.xml:114
#, no-c-format
msgid "Anonymous Memory"
msgstr ""

#. Tag: para
#: tuning_memory.xml:115
#, no-c-format
msgid ""
"Anonymous memory tends to be program heap and stack memory (for example, "
"<literal>&gt;malloc()</literal>). It is reclaimable, except in special cases "
"such as <literal>mlock</literal> or if there is no available swap space. "
"Anonymous memory must be written to swap before it can be reclaimed. Swap I/"
"O (both swapping in and swapping out pages) tends to be less efficient than "
"pagecache I/O, because of allocation and access patterns."
msgstr ""

#. Tag: title
#: tuning_memory.xml:127
#, no-c-format
msgid "Pagecache"
msgstr ""

#. Tag: para
#: tuning_memory.xml:128
#, no-c-format
msgid ""
"A cache of file data. When a file is read from disk or network, the contents "
"are stored in pagecache. No disk or network access is required, if the "
"contents are up-to-date in pagecache. tmpfs and shared memory segments count "
"toward pagecache."
msgstr ""

#. Tag: para
#: tuning_memory.xml:134
#, no-c-format
msgid ""
"When a file is written to, the new data is stored in pagecache before being "
"written back to a disk or the network (making it a write-back cache). When a "
"page has new data not written back yet, it is called <quote>dirty</quote>. "
"Pages not classified as dirty are <quote>clean</quote>. Clean pagecache "
"pages can be reclaimed if there is a memory shortage by simply freeing them. "
"Dirty pages must first be made clean before being reclaimed."
msgstr ""

#. Tag: title
#: tuning_memory.xml:146
#, no-c-format
msgid "Buffercache"
msgstr ""

#. Tag: para
#: tuning_memory.xml:147
#, no-c-format
msgid ""
"This is a type of pagecache for block devices (for example, /dev/sda). A "
"file system typically uses the buffercache when accessing its on-disk "
"metadata structures such as inode tables, allocation bitmaps, and so forth. "
"Buffercache can be reclaimed similarly to pagecache."
msgstr ""

#. Tag: title
#: tuning_memory.xml:156
#, no-c-format
msgid "Buffer Heads"
msgstr ""

#. Tag: para
#: tuning_memory.xml:157
#, no-c-format
msgid ""
"Buffer heads are small auxiliary structures that tend to be allocated upon "
"pagecache access. They can generally be reclaimed easily when the pagecache "
"or buffercache pages are clean."
msgstr ""

#. Tag: title
#: tuning_memory.xml:165
#, no-c-format
msgid "Writeback"
msgstr ""

#. Tag: para
#: tuning_memory.xml:166
#, no-c-format
msgid ""
"As applications write to files, the pagecache becomes dirty and the "
"buffercache may become dirty. When the amount of dirty memory reaches a "
"specified number of pages in bytes (<emphasis>vm.dirty_background_bytes</"
"emphasis>), or when the amount of dirty memory reaches a specific ratio to "
"total memory (<emphasis>vm.dirty_background_ratio</emphasis>), or when the "
"pages have been dirty for longer than a specified amount of time "
"(<emphasis>vm.dirty_expire_centisecs)</emphasis>), the kernel begins "
"writeback of pages starting with files that had the pages dirtied first. The "
"background bytes and ratios are mutually exclusive and setting one will "
"overwrite the other. Flusher threads perform writeback in the background and "
"allow applications to continue running. If the I/O cannot keep up with "
"applications dirtying pagecache, and dirty data reaches a critical setting "
"(<emphasis>vm.dirty_bytes</emphasis> or <emphasis>vm.dirty_ratio</"
"emphasis>), then applications begin to be throttled to prevent dirty data "
"exceeding this threshold."
msgstr ""

#. Tag: title
#: tuning_memory.xml:187
#, no-c-format
msgid "Readahead"
msgstr ""

#. Tag: para
#: tuning_memory.xml:188
#, no-c-format
msgid ""
"The VM monitors file access patterns and may attempt to perform readahead. "
"Readahead reads pages into the pagecache from the file system that have not "
"been requested yet. It is done to allow fewer, larger I/O requests to be "
"submitted (more efficient). And for I/O to be pipelined (I/O performed at "
"the same time as the application is running)."
msgstr ""

#. Tag: title
#: tuning_memory.xml:199
#, no-c-format
msgid "VFS caches"
msgstr ""

#. Tag: title
#: tuning_memory.xml:202
#, no-c-format
msgid "Inode Cache"
msgstr ""

#. Tag: para
#: tuning_memory.xml:203
#, no-c-format
msgid ""
"This is an in-memory cache of the inode structures for each file system. "
"These contain attributes such as the file size, permissions and ownership, "
"and pointers to the file data."
msgstr ""

#. Tag: title
#: tuning_memory.xml:210
#, no-c-format
msgid "Directory Entry Cache"
msgstr ""

#. Tag: para
#: tuning_memory.xml:211
#, no-c-format
msgid ""
"This is an in-memory cache of the directory entries in the system. These "
"contain a name (the name of a file), the inode which it refers to, and "
"children entries. This cache is used when traversing the directory structure "
"and accessing a file by name."
msgstr ""

#. Tag: title
#: tuning_memory.xml:221
#, no-c-format
msgid "Reducing Memory Usage"
msgstr ""

#. Tag: title
#: tuning_memory.xml:226
#, no-c-format
msgid "Reducing malloc (Anonymous) Usage"
msgstr ""

#. Tag: para
#: tuning_memory.xml:227
#, no-c-format
msgid ""
"Applications running on &productname; &productnumber; can allocate more "
"memory compared to &productname; 10. This is because of <systemitem class="
"\"resource\">glibc</systemitem> changing its default behavior while "
"allocating user space memory. See <link xlink:href=\"http://www.gnu.org/s/"
"libc/manual/html_node/Malloc-Tunable-Parameters.html\"></link> for "
"explanation of these parameters."
msgstr ""

#. Tag: para
#: tuning_memory.xml:235
#, no-c-format
msgid ""
"To restore a &productname; 10-like behavior, M_MMAP_THRESHOLD should be set "
"to 128*1024. This can be done with mallopt() call from the application, or "
"via setting MALLOC_MMAP_THRESHOLD environment variable before running the "
"application."
msgstr ""

#. Tag: title
#: tuning_memory.xml:244
#, no-c-format
msgid "Reducing Kernel Memory Overheads"
msgstr ""

#. Tag: para
#: tuning_memory.xml:245
#, no-c-format
msgid ""
"Kernel memory that is reclaimable (caches, described above) will be trimmed "
"automatically during memory shortages. Most other kernel memory cannot be "
"easily reduced but is a property of the workload given to the kernel."
msgstr ""

#. Tag: para
#: tuning_memory.xml:251
#, no-c-format
msgid ""
"Reducing the requirements of the user space workload will reduce the kernel "
"memory usage (fewer processes, fewer open files and sockets, etc.)"
msgstr ""

#. Tag: title
#: tuning_memory.xml:259
#, no-c-format
msgid "Memory Controller (Memory Cgroups)"
msgstr ""

#. Tag: para
#: tuning_memory.xml:260
#, no-c-format
msgid ""
"If the memory cgroups feature is not needed, it can be switched off by "
"passing cgroup_disable=memory on the kernel command line, reducing memory "
"consumption of the kernel a bit. There is also a slight performance benefit "
"as there is a small amount of accounting overhead when memory cgroups are "
"available even if none are configured."
msgstr ""

#. Tag: title
#: tuning_memory.xml:270
#, no-c-format
msgid "Virtual Memory Manager (VM) Tunable Parameters"
msgstr ""

#. Tag: para
#: tuning_memory.xml:272
#, no-c-format
msgid ""
"When tuning the VM it should be understood that some changes will take time "
"to affect the workload and take full effect. If the workload changes "
"throughout the day, it may behave very differently at different times. A "
"change that increases throughput under some conditions may decrease it under "
"other conditions."
msgstr ""

#. Tag: title
#: tuning_memory.xml:281
#, no-c-format
msgid "Reclaim Ratios"
msgstr ""

#. Tag: filename
#: tuning_memory.xml:284
#, no-c-format
msgid "/proc/sys/vm/swappiness"
msgstr ""

#. Tag: para
#: tuning_memory.xml:287
#, no-c-format
msgid ""
"This control is used to define how aggressively the kernel swaps out "
"anonymous memory relative to pagecache and other caches. Increasing the "
"value increases the amount of swapping. The default value is <literal>60</"
"literal>."
msgstr ""

#. Tag: para
#: tuning_memory.xml:293
#, no-c-format
msgid ""
"Swap I/O tends to be much less efficient than other I/O. However, some "
"pagecache pages will be accessed much more frequently than less used "
"anonymous memory. The right balance should be found here."
msgstr ""

#. Tag: para
#: tuning_memory.xml:298
#, no-c-format
msgid ""
"If swap activity is observed during slowdowns, it may be worth reducing this "
"parameter. If there is a lot of I/O activity and the amount of pagecache in "
"the system is rather small, or if there are large dormant applications "
"running, increasing this value might improve performance."
msgstr ""

#. Tag: para
#: tuning_memory.xml:305
#, no-c-format
msgid ""
"Note that the more data is swapped out, the longer the system will take to "
"swap data back in when it is needed."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:312
#, no-c-format
msgid "/proc/sys/vm/vfs_cache_pressure"
msgstr ""

#. Tag: para
#: tuning_memory.xml:315
#, no-c-format
msgid ""
"This variable controls the tendency of the kernel to reclaim the memory "
"which is used for caching of VFS caches, versus pagecache and swap. "
"Increasing this value increases the rate at which VFS caches are reclaimed."
msgstr ""

#. Tag: para
#: tuning_memory.xml:321
#, no-c-format
msgid ""
"It is difficult to know when this should be changed, other than by "
"experimentation. The <command>slabtop</command> command (part of the package "
"<systemitem class=\"resource\">procps</systemitem>) shows top memory objects "
"used by the kernel. The vfs caches are the \"dentry\" and the \"*_inode_cache"
"\" objects. If these are consuming a large amount of memory in relation to "
"pagecache, it may be worth trying to increase pressure. Could also help to "
"reduce swapping. The default value is <literal>100</literal>."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:334
#, no-c-format
msgid "/proc/sys/vm/min_free_kbytes"
msgstr ""

#. Tag: para
#: tuning_memory.xml:337
#, no-c-format
msgid ""
"This controls the amount of memory that is kept free for use by special "
"reserves including <quote>atomic</quote> allocations (those which cannot "
"wait for reclaim). This should not normally be lowered unless the system is "
"being very carefully tuned for memory usage (normally useful for embedded "
"rather than server applications). If <quote>page allocation failure</quote> "
"messages and stack traces are frequently seen in logs, min_free_kbytes could "
"be increased until the errors disappear. There is no need for concern, if "
"these messages are very infrequent. The default value depends on the amount "
"of RAM."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:351
#, no-c-format
msgid "/proc/sys/vm/watermark_scale_factor"
msgstr ""

#. Tag: para
#: tuning_memory.xml:353
#, no-c-format
msgid ""
"Broadly speaking, free memory has high, low and min watermarks. When the low "
"watermark is reached then <command>kswapd</command> wakes to reclaim memory "
"in the background. It stays awake until free memory reaches the high "
"watermark. Applications will stall and reclaim memory when the low watermark "
"is reached."
msgstr ""

#. Tag: para
#: tuning_memory.xml:360
#, no-c-format
msgid ""
"The <literal>watermark_scale_factor</literal> defines the amount of memory "
"left in a node/system before kswapd is woken up and how much memory needs to "
"be free before kswapd goes back to sleep. The unit is in fractions of "
"10,000. The default value of 10 means the distances between watermarks are "
"0.1% of the available memory in the node/system. The maximum value is 1000, "
"or 10% of memory."
msgstr ""

#. Tag: para
#: tuning_memory.xml:368
#, no-c-format
msgid ""
"Workloads that frequently stall in direct reclaim, accounted by "
"<literal>allocstall</literal> in <filename>/proc/vmstat</filename>, may "
"benefit from altering this parameter. Similarly, if <command>kswapd</"
"command> is sleeping prematurely, as accounted for by "
"<literal>kswapd_low_wmark_hit_quickly</literal>, then it may indicate that "
"the number of pages kept free to avoid stalls is too low."
msgstr ""

#. Tag: title
#: tuning_memory.xml:382
#, no-c-format
msgid "Writeback Parameters"
msgstr ""

#. Tag: para
#: tuning_memory.xml:383
#, no-c-format
msgid ""
"One important change in writeback behavior since &productname; 10 is that "
"modification to file-backed mmap() memory is accounted immediately as dirty "
"memory (and subject to writeback). Whereas previously it would only be "
"subject to writeback after it was unmapped, upon an msync() system call, or "
"under heavy memory pressure."
msgstr ""

#. Tag: para
#: tuning_memory.xml:390
#, no-c-format
msgid ""
"Some applications do not expect mmap modifications to be subject to such "
"writeback behavior, and performance can be reduced. Berkeley DB (and "
"applications using it) is one known example that can cause problems. "
"Increasing writeback ratios and times can improve this type of slowdown."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:398
#, no-c-format
msgid "/proc/sys/vm/dirty_background_ratio"
msgstr ""

#. Tag: para
#: tuning_memory.xml:401
#, no-c-format
msgid ""
"This is the percentage of the total amount of free and reclaimable memory. "
"When the amount of dirty pagecache exceeds this percentage, writeback "
"threads start writing back dirty memory. The default value is <literal>10</"
"literal> (%)."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:410
#, no-c-format
msgid "/proc/sys/vm/dirty_background_bytes"
msgstr ""

#. Tag: para
#: tuning_memory.xml:413
#, no-c-format
msgid ""
"This contains the amount of dirty memory at which the background kernel "
"flusher threads will start writeback. <filename>dirty_background_bytes</"
"filename> is the counterpart of <filename>dirty_background_ratio</filename>. "
"If one of them is set, the other one will automatically be read as "
"<literal>0</literal>."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:423
#, no-c-format
msgid "/proc/sys/vm/dirty_ratio"
msgstr ""

#. Tag: para
#: tuning_memory.xml:426
#, no-c-format
msgid ""
"Similar percentage value as for <filename>dirty_background_ratio</filename>. "
"When this is exceeded, applications that want to write to the pagecache are "
"blocked and wait for kernel background flusher threads to reduce amount of "
"dirty memory. The default value is <literal>20</literal> (%)."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:436
#, no-c-format
msgid "/proc/sys/vm/dirty_bytes"
msgstr ""

#. Tag: para
#: tuning_memory.xml:439
#, no-c-format
msgid ""
"This file controls the same tunable as <filename>dirty_ratio</filename> "
"however the amount of dirty memory is in bytes as opposed to a percentage of "
"reclaimable memory. Since both <filename>dirty_ratio</filename> and "
"<filename>dirty_bytes</filename> control the same tunable, if one of them is "
"set, the other one will automatically be read as <literal>0</literal>. The "
"minimum value allowed for <filename>dirty_bytes</filename> is two pages (in "
"bytes); any value lower than this limit will be ignored and the old "
"configuration will be retained."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:453
#, no-c-format
msgid "/proc/sys/vm/dirty_expire_centisecs"
msgstr ""

#. Tag: para
#: tuning_memory.xml:456
#, no-c-format
msgid ""
"Data which has been dirty in-memory for longer than this interval will be "
"written out next time a flusher thread wakes up. Expiration is measured "
"based on the modification time of a file's inode. Therefore, multiple "
"dirtied pages from the same file will all be written when the interval is "
"exceeded."
msgstr ""

#. Tag: para
#: tuning_memory.xml:466
#, no-c-format
msgid ""
"<filename>dirty_background_ratio</filename> and <filename>dirty_ratio</"
"filename> together determine the pagecache writeback behavior. If these "
"values are increased, more dirty memory is kept in the system for a longer "
"time. With more dirty memory allowed in the system, the chance to improve "
"throughput by avoiding writeback I/O and to submitting more optimal I/O "
"patterns increases. However, more dirty memory can either harm latency when "
"memory needs to be reclaimed or at points of data integrity "
"(<quote>synchronization points</quote>) when it needs to be written back to "
"disk."
msgstr ""

#. Tag: title
#: tuning_memory.xml:480
#, no-c-format
msgid "Timing Differences of I/O Writes between &sle; 12 and &sle; 11"
msgstr ""

#. Tag: para
#: tuning_memory.xml:481
#, no-c-format
msgid ""
"The system is required to limit what percentage of the system's memory "
"contains file-backed data that needs writing to disk. This guarantees that "
"the system can always allocate the necessary data structures to complete I/"
"O. The maximum amount of memory that may be dirty and requires writing at "
"any given time is controlled by <literal>vm.dirty_ratio</literal> "
"(<filename>/proc/sys/vm/dirty_ratio</filename>). The defaults are:"
msgstr ""

#. Tag: screen
#: tuning_memory.xml:490
#, no-c-format
msgid ""
"SLE-11-SP3:     vm.dirty_ratio = 40\n"
"SLE-12:         vm.dirty_ratio = 20"
msgstr ""

#. Tag: para
#: tuning_memory.xml:491
#, no-c-format
msgid ""
"The primary advantage of using the lower ratio in &sle; 12 is that page "
"reclamation and allocation in low memory situations completes faster as "
"there is a higher probability that old clean pages will be quickly found and "
"discarded. The secondary advantage is that if all data on the system must be "
"synchronized, then the time to complete the operation on &sle; 12 will be "
"lower than &sle; 11 SP3 by default. Most workloads will not notice this "
"change as data is synchronized with <literal>fsync()</literal> by the "
"application or data is not dirtied quickly enough to hit the limits."
msgstr ""

#. Tag: para
#: tuning_memory.xml:502
#, no-c-format
msgid ""
"There are exceptions and if your application is affected by this, it will "
"manifest as an unexpected stall during writes. To prove it is affected by "
"dirty data rate limiting then monitor <literal>/proc/"
"<replaceable>PID_OF_APPLICATION</replaceable>/stack</literal> and it will be "
"observed that the application spends significant time in "
"<literal>balance_dirty_pages_ratelimited</literal>. If this is observed and "
"it is a problem, then increase the value of <literal>vm.dirty_ratio</"
"literal> to 40 to restore the &sle; 11 SP3 behavior."
msgstr ""

#. Tag: para
#: tuning_memory.xml:513
#, no-c-format
msgid ""
"It is important to note that the overall I/O throughput is the same "
"regardless of the setting. The only difference is the timing of when the I/O "
"is queued."
msgstr ""

#. Tag: para
#: tuning_memory.xml:518
#, no-c-format
msgid ""
"This is an example of using <command>dd</command> to asynchronously write "
"30% of memory to disk which would happen to be affected by the change in "
"<literal>vm.dirty_ratio</literal>:"
msgstr ""

#. Tag: screen
#: tuning_memory.xml:523
#, no-c-format
msgid ""
"&prompt.root;MEMTOTAL_MBYTES=`free -m | grep Mem: | awk '{print $2}'`\n"
"&prompt.root;sysctl vm.dirty_ratio=40\n"
"&prompt.root;dd if=/dev/zero of=zerofile ibs=1048576 count="
"$((MEMTOTAL_MBYTES*30/100))\n"
"2507145216 bytes (2.5 GB) copied, 8.00153 s, 313 MB/s\n"
"&prompt.root;sysctl vm.dirty_ratio=20\n"
"dd if=/dev/zero of=zerofile ibs=1048576 count=$((MEMTOTAL_MBYTES*30/100))\n"
"2507145216 bytes (2.5 GB) copied, 10.1593 s, 247 MB/s"
msgstr ""

#. Tag: para
#: tuning_memory.xml:524
#, no-c-format
msgid ""
"Note that the parameter affects the time it takes for the command to "
"complete and the apparent write speed of the device. With "
"<literal>dirty_ratio=40</literal>, more of the data is cached and written to "
"disk in the background by the kernel. It is very important to note that the "
"speed of I/O is identical in both cases. To demonstrate, this is the result "
"when <command>dd</command> synchronizes the data before exiting:"
msgstr ""

#. Tag: screen
#: tuning_memory.xml:533
#, no-c-format
msgid ""
"&prompt.root;sysctl vm.dirty_ratio=40\n"
"&prompt.root;dd if=/dev/zero of=zerofile ibs=1048576 count="
"$((MEMTOTAL_MBYTES*30/100)) conv=fdatasync\n"
"2507145216 bytes (2.5 GB) copied, 21.0663 s, 119 MB/s\n"
"&prompt.root;sysctl vm.dirty_ratio=20\n"
"&prompt.root;dd if=/dev/zero of=zerofile ibs=1048576 count="
"$((MEMTOTAL_MBYTES*30/100)) conv=fdatasync\n"
"2507145216 bytes (2.5 GB) copied, 21.7286 s, 115 MB/s"
msgstr ""

#. Tag: para
#: tuning_memory.xml:534
#, no-c-format
msgid ""
"Note that <literal>dirty_ratio</literal> had almost no impact here and is "
"within the natural variability of a command. Hence, <literal>dirty_ratio</"
"literal> does not directly impact I/O performance but it may affect the "
"apparent performance of a workload that writes data asynchronously without "
"synchronizing."
msgstr ""

#. Tag: title
#: tuning_memory.xml:544
#, no-c-format
msgid "Readahead Parameters"
msgstr ""

#. Tag: filename
#: tuning_memory.xml:547
#, no-c-format
msgid "/sys/block/<replaceable>&lt;bdev&gt;</replaceable>/queue/read_ahead_kb"
msgstr ""

#. Tag: para
#: tuning_memory.xml:550
#, no-c-format
msgid ""
"If one or more processes are sequentially reading a file, the kernel reads "
"some data in advance (ahead) to reduce the amount of time that processes "
"need to wait for data to be available. The actual amount of data being read "
"in advance is computed dynamically, based on how much \"sequential\" the I/O "
"seems to be. This parameter sets the maximum amount of data that the kernel "
"reads ahead for a single file. If you observe that large sequential reads "
"from a file are not fast enough, you can try increasing this value. "
"Increasing it too far may result in readahead thrashing where pagecache used "
"for readahead is reclaimed before it can be used, or slowdowns because of a "
"large amount of useless I/O. The default value is <literal>512</literal> "
"(KB)."
msgstr ""

#. Tag: title
#: tuning_memory.xml:570
#, no-c-format
msgid "Transparent Huge Page Parameters"
msgstr ""

#. Tag: para
#: tuning_memory.xml:571
#, no-c-format
msgid ""
"Transparent Huge Pages (THP) provide a way to dynamically allocate huge "
"pages either on-demand by the process or deferring the allocation until "
"later via the <command>khugepaged</command> kernel thread. This method is "
"distinct from the use of <literal>hugetlbfs</literal> to manually manage "
"their allocation and use. Workloads with contiguous memory access patterns "
"can benefit greatly from THP. A 1000 fold decrease in page faults can be "
"observed when running synthetic workloads with contiguous memory access "
"patterns."
msgstr ""

#. Tag: para
#: tuning_memory.xml:581
#, no-c-format
msgid ""
"There are cases when THP may be undesirable. Workloads with sparse memory "
"access patterns may perform poorly with THP due to excessive memory usage. "
"For example, 2 MB of memory may be used at fault time instead of 4 KB for "
"each fault and ultimately lead to premature page reclaim. On releases older "
"then &sle; 12 SP2, it was possible for an application to stall for long "
"periods of time trying to allocate a THP which frequently led to a "
"recommendation of disabling THP. Such recommendations should be re-evaluated "
"for &sle; 12 SP2."
msgstr ""

#. Tag: para
#: tuning_memory.xml:591
#, no-c-format
msgid ""
"The behaviour of THP may be configured via the "
"<option>transparent_hugepage=</option> kernel parameter or via sysfs. For "
"example, it may be disabled by adding the kernel parameter "
"<option>transparent_hugepage=never</option>, rebuild your grub2 "
"configuration, and reboot. Verify if THP is disabled with:"
msgstr ""

#. Tag: screen
#: tuning_memory.xml:599
#, no-c-format
msgid ""
"&prompt.root;cat /sys/kernel/mm/transparent_hugepage/enabled\n"
"always madvise [never]"
msgstr ""

#. Tag: para
#: tuning_memory.xml:600
#, no-c-format
msgid ""
"If disabled, the value <literal>never</literal> is shown in square brackets "
"like in the example above. A value of <literal>always</literal> will always "
"try and use THP at fault time but defer to <command>khugepaged</command> if "
"the allocation fails. A value of <literal>madvise</literal> will only "
"allocate THP for address spaces explicitly specified by an application."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:610
#, no-c-format
msgid "/sys/kernel/mm/transparent_hugepage/defrag"
msgstr ""

#. Tag: para
#: tuning_memory.xml:613
#, no-c-format
msgid ""
"This parameter controls how much effort an application commits when "
"allocating a THP. A value of <literal>always</literal> is the default for "
"&sle; 12 SP1 and earlier releases that supported THP. If a THP is not "
"available, the application will try to defragment memory. It potentially "
"incurs large stalls in an application if the memory is fragmented and a THP "
"is not available."
msgstr ""

#. Tag: para
#: tuning_memory.xml:621
#, no-c-format
msgid ""
"A value of <literal>madvise</literal> means that THP allocation requests "
"will only defragment if the application explicitly requests it. This is the "
"default for &sle; 12 SP2."
msgstr ""

#. Tag: para
#: tuning_memory.xml:626
#, no-c-format
msgid ""
"<literal>defer</literal> is only available on &sle; 12 SP2 and later "
"releases. If a THP is not available, the application will fallback to using "
"small pages if a THP is not available. It will wake the <command>kswapd</"
"command> and <command>kcompactd</command> kernel threads to defragment "
"memory in the background and a THP will be allocated later "
"<command>khugepaged</command>."
msgstr ""

#. Tag: para
#: tuning_memory.xml:634
#, no-c-format
msgid ""
"The final option <literal>never</literal> will use small pages if a THP is "
"unavailable but no other action will take place."
msgstr ""

#. Tag: title
#: tuning_memory.xml:643
#, no-c-format
msgid "khugepaged Parameters"
msgstr ""

#. Tag: para
#: tuning_memory.xml:644
#, no-c-format
msgid ""
"khugepaged will be automatically started when <literal>transparent_hugepage</"
"literal> is set to <literal>always</literal> or <literal>madvise</literal>, "
"and it'll be automatically shutdown if it's set to <literal>never</literal>. "
"Normally this runs at low frequency but the behaviour can be tuned."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:653
#, no-c-format
msgid "/sys/kernel/mm/transparent_hugepage/khugepaged/defrag"
msgstr ""

#. Tag: para
#: tuning_memory.xml:655
#, no-c-format
msgid ""
"A value of 0 will disable <command>khugepaged</command> even though THP may "
"still be used at fault time. This may be important for latency-sensitive "
"applications that benefit from THP but cannot tolerate a stall if "
"<command>khugepaged</command> tries update an applications memory usage."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:666
#, no-c-format
msgid "/sys/kernel/mm/transparent_hugepage/khugepaged/pages_to_scan"
msgstr ""

#. Tag: para
#: tuning_memory.xml:668
#, no-c-format
msgid ""
"This parameter controls how many pages are scanned by <command>khugepaged</"
"command> in a single pass. A scan identifies small pages that can be "
"reallocated as THP. Increasing this value will allocate THP in the "
"background faster at the cost of CPU usage."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:679
#, no-c-format
msgid "/sys/kernel/mm/transparent_hugepage/khugepaged/scan_sleep_millisecs"
msgstr ""

#. Tag: para
#: tuning_memory.xml:681
#, no-c-format
msgid ""
"<command>khugepaged</command> sleeps for a short interval specified by this "
"parameter after each pass to limit how much CPU usage is used. Reducing this "
"value will allocate THP in the background faster at the cost of CPU usage. A "
"value of 0 will force continual scanning."
msgstr ""

#. Tag: filename
#: tuning_memory.xml:691
#, no-c-format
msgid "/sys/kernel/mm/transparent_hugepage/khugepaged/alloc_sleep_millisecs"
msgstr ""

#. Tag: para
#: tuning_memory.xml:694
#, no-c-format
msgid ""
"This parameter controls how long <command>khugepaged</command> will sleep in "
"the event it fails to allocate a THP in the background waiting for "
"<command>kswapd</command> and <command>kcompactd</command> to take action."
msgstr ""

#. Tag: para
#: tuning_memory.xml:704
#, no-c-format
msgid ""
"The remaining parameters for <command>khugepaged</command> are rarely useful "
"for performance tuning but are fully documented in <filename>/usr/src/linux/"
"Documentation/vm/transhuge.txt</filename>"
msgstr ""

#. Tag: title
#: tuning_memory.xml:711
#, no-c-format
msgid "Further VM Parameters"
msgstr ""

#. Tag: para
#: tuning_memory.xml:712
#, no-c-format
msgid ""
"For the complete list of the VM tunable parameters, see <filename>/usr/src/"
"linux/Documentation/sysctl/vm.txt</filename> (available after having "
"installed the <systemitem class=\"resource\">kernel-source</systemitem> "
"package)."
msgstr ""

#. Tag: title
#: tuning_memory.xml:757
#, no-c-format
msgid "Monitoring VM Behavior"
msgstr ""

#. Tag: para
#: tuning_memory.xml:759
#, no-c-format
msgid "Some simple tools that can help monitor VM behavior:"
msgstr ""

#. Tag: para
#: tuning_memory.xml:765
#, no-c-format
msgid ""
"vmstat: This tool gives a good overview of what the VM is doing. See <xref "
"linkend=\"sec.util.multi.vmstat\"/> for details."
msgstr ""

#. Tag: para
#: tuning_memory.xml:771
#, no-c-format
msgid ""
"<filename>/proc/meminfo</filename>: This file gives a detailed breakdown of "
"where memory is being used. See <xref linkend=\"sec.util.memory.meminfo\"/> "
"for details."
msgstr ""

#. Tag: para
#: tuning_memory.xml:778
#, no-c-format
msgid ""
"<command>slabtop</command>: This tool provides detailed information about "
"kernel slab memory usage. buffer_head, dentry, inode_cache, "
"ext3_inode_cache, etc. are the major caches. This command is available with "
"the package <systemitem class=\"resource\">procps</systemitem>."
msgstr ""

#. Tag: para
#: tuning_memory.xml:786
#, no-c-format
msgid ""
"<filename>/proc/vmstat</filename>: This file gives a detailed breakdown of "
"internal VM behaviour. The information contained within is implementation "
"specific and may not always be available. Some of the information is "
"duplicated in <filename>/proc/meminfo</filename> and others can be presented "
"in a friendly fashion by utilties. For maximum utility, this file needs to "
"be monitored over time to observe rates of change. The most important pieces "
"of information that are hard to derive from other sources are as follows;"
msgstr ""

#. Tag: literal
#: tuning_memory.xml:798
#, no-c-format
msgid "pgscan_kswapd_*, pgsteal_kswapd_*"
msgstr ""

#. Tag: para
#: tuning_memory.xml:800
#, no-c-format
msgid ""
"These report respectively the number of pages scanned and reclaimed by "
"<command>kswapd</command> since the system started. The ratio between these "
"values can be interpreted as the reclaim efficiency with a low efficiency "
"implying that the system is struggling to reclaim memory and may be "
"thrashing. Light activity here is generally not something to be concerned "
"with."
msgstr ""

#. Tag: literal
#: tuning_memory.xml:811
#, no-c-format
msgid "pgscan_direct_*, pgsteal_direct_*"
msgstr ""

#. Tag: para
#: tuning_memory.xml:813
#, no-c-format
msgid ""
"These report respectively the number of pages scanned and reclaimed by an "
"application directly. It is correlated with increases in the "
"<literal>allocstall</literal> counter. This is more serious than "
"<command>kswapd</command> activity as these events indicate that processes "
"are stalling. Heavy activity here combined with <command>kswapd</command> "
"and high rates of <literal>pgpgin</literal>, <literal>pgpout</literal> and/"
"or high rates of <literal>pswapin</literal> or <literal>pswpout</literal> "
"are signs that a system is thrashing heavily."
msgstr ""

#. Tag: para
#: tuning_memory.xml:824
#, no-c-format
msgid "More detailed information can be obtained using tracepoints."
msgstr ""

#. Tag: literal
#: tuning_memory.xml:830
#, no-c-format
msgid "thp_fault_alloc, thp_fault_fallback"
msgstr ""

#. Tag: para
#: tuning_memory.xml:832
#, no-c-format
msgid ""
"These counters correspond to how many THPs were allocated directly by an "
"application and how many times a THP was not available and small pages were "
"used. Generally a high fallback rate is harmless unless the application is "
"very sensitive to TLB pressure."
msgstr ""

#. Tag: literal
#: tuning_memory.xml:841
#, no-c-format
msgid "thp_collapse_alloc, thp_collapse_alloc_failed"
msgstr ""

#. Tag: para
#: tuning_memory.xml:843
#, no-c-format
msgid ""
"These counters correspond to how many THPs were allocated by "
"<command>khugepaged</command> and how many times a THP was not available and "
"small pages were used. A high fallback rate implies that the system is "
"fragmented and THPs are not being used even when the memory usage by "
"applications would allow them. It is only a problem for applications that "
"are sensitive to TLB pressure."
msgstr ""

#. Tag: literal
#: tuning_memory.xml:854
#, no-c-format
msgid "compact_*_scanned, compact_stall, compact_fail, compact_success"
msgstr ""

#. Tag: para
#: tuning_memory.xml:856
#, no-c-format
msgid ""
"These counters may increase when THP is enabled and the system is "
"fragmented. <literal>compact_stall</literal> is incremented when an "
"application stalls allocating THP. The remaining counters account for pages "
"scanned, the number of defragmentation events that succeeded or failed."
msgstr ""
